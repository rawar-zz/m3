{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styletransfer mit Keras\n",
    "\n",
    "Voraussetzung:\n",
    "https://dl.dropboxusercontent.com/u/108721752/imagenet-vgg-verydeep-19.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Image\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quell- und Stilbild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_file_name = 'london.jpg'\n",
    "style_file_name = '1-style.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_content = scipy.misc.imread(content_file_name)\n",
    "plt.figure(figsize=(11,11))\n",
    "plt.imshow(image_content)\n",
    "image_content = image_content.astype('float32')\n",
    "image_content = np.ndarray.reshape(image_content,((1,) + image_content.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_style = scipy.misc.imread(style_file_name)\n",
    "plt.figure(figsize=(11,11))\n",
    "plt.imshow(image_style)\n",
    "image_style = image_style.astype('float32')\n",
    "image_style = np.ndarray.reshape(image_style,((1,) + image_style.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_content.shape)\n",
    "print(image_style.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19 laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('./imagenet-vgg-verydeep-19.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ein paar Hilfsfunktionen für das KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return (image - mean_pixel).astype('float32')\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return (image + mean_pixel).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN mit Tensorflow (tf.nn) erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(input_image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "    weights = data['layers'][0]\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        print(i,name)\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "    assert len(net) == len(layers)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN mit Keras erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_model(input_image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "    weights = data['layers'][0]\n",
    "    model = Sequential()\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        print(i,name)\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            print(kernels.shape, bias.shape)\n",
    "            kernels_keras = np.transpose(kernels, (1,0,2,3))\n",
    "           \n",
    "            if i==0:\n",
    "                model.add(ZeroPadding2D((1,1),data_format=\"channels_first\",input_shape=(input_image.shape[3],input_image.shape[1],input_image.shape[2])))\n",
    "            else:\n",
    "                model.add(ZeroPadding2D((1,1),data_format=\"channels_first\"))\n",
    "            \n",
    "            print(model.layers[i].input)\n",
    "            print(model.layers[i].output)\n",
    "            model.add(Conv2D(bias.size, (3, 3), name=name, data_format=\"channels_first\", weights=[kernels_keras,bias[0]])) \n",
    "        elif kind == 'relu':\n",
    "            model.add(Activation('relu', name=name))\n",
    "        elif kind == 'pool':\n",
    "            model.add(MaxPooling2D((2,2), data_format=\"channels_first\", name=name, border_mode='same', strides=(2,2)))\n",
    "             \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berechnet den Pixel-Wert-Durchschnitt des VGG19. Dieser Wert wird für die Nomalisierung genutzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['normalization'][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = data['normalization'][0][0][0]\n",
    "mean_pixel = np.mean(mean, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Das Zielbild wird vorverarbeitet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_pre = preprocess(image_content, mean_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktivitätsberechnung des VGG19 Netzwerks auf dem content_pre Bild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_keras_model = keras_model(content_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = net(content_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer für die Nutzung als Inhalts-Feature auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENT_LAYERS = ('conv1_1', 'conv2_1', 'conv4_1', 'conv4_2')\n",
    "content_features = {}\n",
    "content_keras_features ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CONTENT_LAYERS:\n",
    "    tmpmodel=Model(inputs=content_keras_model.input, outputs=content_keras_model.get_layer(layer).output) \n",
    "    content_keras_features[layer]=np.transpose(tmpmodel.predict(np.transpose(content_pre,(0,3,1,2)) ),(0,2,3,1))\n",
    "    print('content_keras_feaures shape:', layer, content_keras_features[layer].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Im neuen Zielbild werden die Inhalts-Features verglichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features=content_keras_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer für die Nutzng als Style-Feature auswählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
    "style_pre = preprocess(image_style, mean_pixel)\n",
    "style_keras_model = keras_model(style_pre)\n",
    "style_keras_features ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in STYLE_LAYERS:\n",
    "    \n",
    "    tmpmodel=Model(\n",
    "        inputs=style_keras_model.input, \n",
    "        outputs=style_keras_model.get_layer(layer).output\n",
    "    ) \n",
    "    \n",
    "    features=np.transpose(tmpmodel.predict(np.transpose(style_pre,(0,3,1,2)) ),(0,2,3,1))\n",
    "    print('features shape:', layer, features.shape)\n",
    "    \n",
    "    features = np.reshape(features, (-1, features.shape[3]))\n",
    "    print('reshaped features shape:', layer, features.shape)\n",
    "    \n",
    "    gram = np.matmul(features.T, features) / features.size\n",
    "    style_keras_features[layer] = gram\n",
    "    print('gram shape:', layer, gram.shape)\n",
    "    print('**************')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Im Zielbild werden die Features des Style-Bildes verglichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_features=style_keras_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeuge ein neues initiales Bild mit Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial = None\n",
    "if initial is None:\n",
    "    noise = np.random.normal(size=image_content.shape, scale=np.std(image_content) * 0.1)\n",
    "    initial = tf.random_normal(image_content.shape) * 0.256\n",
    "else:\n",
    "    initial = np.array([preprocess(initial, mean_pixel)])\n",
    "    initial = initial.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Das neue Bild als TensorFlow-Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.Variable(initial)\n",
    "image_net = net(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiale Parameter setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_weight= 5e0\n",
    "style_weight= 1e2\n",
    "tv_weight = 1e2\n",
    "learning_rate = 1e1\n",
    "iterations =  1000\n",
    "checkpoint_iterations = 20\n",
    "print_iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeugen der Content-Verlustfunktion\n",
    "It measure how much the content features of the tensorflow variable \"image\" deviate from the content features of the content image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_loss = 0\n",
    "content_losses = []\n",
    "for content_layer in CONTENT_LAYERS:\n",
    "    content_losses.append(2 * tf.nn.l2_loss(\n",
    "                          image_net[content_layer] - content_features[content_layer]) / \n",
    "                          content_features[content_layer].size)\n",
    "content_loss += content_weight * reduce(tf.add, content_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeuge die Style-Verlustfunktion\n",
    "It measure how much the style Gram matrices of the tensorflow variable \"image\" deviate from the style Gram matrices of the style image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_loss = 0\n",
    "style_losses = []\n",
    "for style_layer in STYLE_LAYERS:\n",
    "    layer = image_net[style_layer]\n",
    "    _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "    size = height * width * number\n",
    "    feats = tf.reshape(layer, (-1, number))\n",
    "    gram = tf.matmul(tf.transpose(feats), feats) / size\n",
    "    style_gram = style_features[style_layer]\n",
    "    style_losses.append(2 * tf.nn.l2_loss(gram - style_gram) / style_gram.size)\n",
    "style_loss += style_weight * reduce(tf.add, style_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeugung einer \"Total Variation\" Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv_y_size = _tensor_size(image[:,1:,:,:])\n",
    "tv_x_size = _tensor_size(image[:,:,1:,:])\n",
    "tv_loss = tv_weight * 2 * (\n",
    "        (tf.nn.l2_loss(image[:,1:,:,:] - image[:,:image_content.shape[1]-1,:,:]) /\n",
    "            tv_y_size) +\n",
    "        (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:image_content.shape[2]-1,:]) /\n",
    "            tv_x_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition der Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = content_loss + style_loss + tv_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nutzung des AdamOptimizers um die Verlustfunktion zu berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimierung starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "best_loss = float('inf')\n",
    "best = None\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(iterations):\n",
    "        print(i)\n",
    "        \n",
    "        # the next step is the actual tensorflow training/minimization step\n",
    "        train_op.run()\n",
    "        \n",
    "        # save the images after some iterations\n",
    "        if i % checkpoint_iterations == 0 or i == iterations - 1:\n",
    "            this_loss = loss.eval()\n",
    "            if this_loss < best_loss:\n",
    "                best_loss = this_loss\n",
    "                \n",
    "                # this is the best image so far\n",
    "                best = image.eval()\n",
    "                print(\"new minimum found\")\n",
    "                newimg= unprocess(best.reshape(image_content.shape[1:]), mean_pixel)\n",
    "                img = np.clip(newimg, 0, 255).astype(np.uint8)\n",
    "                plt.figure(figsize=(11,11))\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "                \n",
    "            \n",
    "            # save a check point\n",
    "            import os\n",
    "            try:\n",
    "                os.makedirs('./checks/'+str.split(content_file_name,'.')[0])\n",
    "            except OSError:\n",
    "                pass\n",
    "            timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename_cp = './checks/'+str.split(content_file_name,'.')[0]+'/'+timestr+'.jpg'\n",
    "            \n",
    "            cp = unprocess(best.reshape(image_content.shape[1:]), mean_pixel)\n",
    "            imsave(filename_cp, cp)\n",
    "           \n",
    "        \n",
    "        if i % print_iterations == 0 or i == iterations - 1:\n",
    "            print('epoch %d/%d' % (i + 1, iterations))\n",
    "            print('  content loss: %g' % content_loss.eval())\n",
    "            print('    style loss: %g' % style_loss.eval())\n",
    "            print('       tv loss: %g' % tv_loss.eval())\n",
    "            print('    total loss: %g' % loss.eval())\n",
    "\n",
    "    output = unprocess(best.reshape(image_content.shape[1:]), mean_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave('output_'+content_file_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = 'output_'+content_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
